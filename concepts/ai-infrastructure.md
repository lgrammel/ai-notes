# AI Infrastructure

AI infrastructure is infrastructure built or adapted to support [LLM](./llm.md) and [agent](./agent.md)-based systems in production, addressing concerns that general-purpose infrastructure does not cover well: GPU compute provisioning, model lifecycle management, [inference](./inference.md)-specific scaling, non-deterministic output handling, and [eval](./evals.md)/[observability](./observability.md) integration.

## Examples

- Model hosting
- [AI gateways](./ai-gateway.md)
- [Observability](./observability.md) for AI systems
- AI search/RAG infrastructure
- [Eval runners](./eval-runner.md)
- [Sandboxes](./sandbox.md) (local or as-a-service)
- [Agent hosting platforms](./agent-hosting-platform.md)
