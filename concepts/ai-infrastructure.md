# AI Infrastructure

AI infrastructure is infrastructure built or adapted to support AI systems in production (especially [LLM](./llm.md) and [agent](./agent.md)-based use cases).

## Details

Compared to general-purpose infrastructure, AI infrastructure addresses concerns specific to model-based systems: GPU compute provisioning, model lifecycle management, [inference](./inference.md)-specific scaling, non-deterministic output handling, and [eval](./evals.md)/[observability](./observability.md) integration.

## Examples

- Model hosting
- [AI gateways](./ai-gateway.md)
- [AI observability](./observability.md)
- AI search/RAG infrastructure
- [Eval runners](./eval-runner.md)
- [Sandboxes](./sandbox.md) (local or as-a-service)
- [Agent hosting platforms](./agent-hosting-platform.md)
