# Evaluations (Evals)

Evals (evaluations) are systematic tests used to measure and monitor [model](./large-language-model.md) or system performance on specific tasks. They are used to compare variants, catch regressions, and track metrics like accuracy, safety, and robustness.

Evals are commonly built from real user traffic and failure cases surfaced by telemetry, and they are often used as release gates when changing [prompts](./prompt.md), tools, [models](./large-language-model.md), or [infrastructure](./ai-infrastructure.md).
